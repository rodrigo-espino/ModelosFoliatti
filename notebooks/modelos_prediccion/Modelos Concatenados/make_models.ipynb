{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9387cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, ElasticNet, HuberRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd96062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_general = pd.read_csv('../../../data/data_general.csv')\n",
    "\n",
    "df_data_general['INITIAL_TIME'] = pd.to_datetime(df_data_general['INITIAL_TIME'])\n",
    "df_data_general['FINAL_TIME'] = pd.to_datetime(df_data_general['FINAL_TIME'])\n",
    "\n",
    "df_data_general['INITIAL_TIME'] = df_data_general['INITIAL_TIME'].dt.to_period('D')\n",
    "df_data_general['INITIAL_TIME'] = df_data_general['INITIAL_TIME'].dt.to_timestamp()\n",
    "\n",
    "\n",
    "df_data_general['FINAL_TIME'] = df_data_general['FINAL_TIME'].dt.to_period('D')\n",
    "df_data_general['FINAL_TIME'] = df_data_general['FINAL_TIME'].dt.to_timestamp()\n",
    "\n",
    "df_data_general['Weekday']= df_data_general['INITIAL_TIME'].dt.strftime('%A')\n",
    "df_data_general['number_of_day'] = df_data_general['INITIAL_TIME'].dt.day_of_week\n",
    "\n",
    "df_data_general['TIME_ON_DEVICE_MIN'] = df_data_general['TIME_ON_DEVICE_SEC'] / 60\n",
    "\n",
    "df_data_general['Hour'] = df_data_general['INITIAL_TIME'].dt.hour\n",
    "df_data_general['Weekday'] = df_data_general['INITIAL_TIME'].dt.weekday   # 0=Lunes, 6=Domingo\n",
    "df_data_general['Weekend'] = (df_data_general['Weekday'] >= 5).astype(int)\n",
    "df_data_general['Month'] = df_data_general['INITIAL_TIME'].dt.month\n",
    "\n",
    "df_data_general = df_data_general[df_data_general['TIME_ON_DEVICE_MIN'] < 600 ]\n",
    "\n",
    "df_data_general = df_data_general[df_data_general['WIN_TOTAL'] > 0]\n",
    "df_data_general['NET_SPEND'] = df_data_general['FINAL_AMOUNT'] - df_data_general['INITIAL_AMOUNT']\n",
    "df_data_general = df_data_general[df_data_general['NET_SPEND'] < 10000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f4bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BusinessLogicCorrectModel:\n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.models = {}\n",
    "        \n",
    "    def create_business_features(self, df, tiempo_pred=None, bet_pred=None, win_pred=None):\n",
    "        \"\"\"\n",
    "        Crear features que reflejen la l√≥gica real del negocio de casino\n",
    "        \"\"\"\n",
    "        features = df[['INITIAL_AMOUNT', 'AVG_BET', 'Cluster']].copy()\n",
    "        \n",
    "        if tiempo_pred is not None:\n",
    "            features['tiempo_pred'] = tiempo_pred\n",
    "            \n",
    "        if bet_pred is not None and win_pred is not None:\n",
    "            # Features que reflejan el comportamiento real del casino\n",
    "            features['bet_pred'] = bet_pred\n",
    "            features['win_pred'] = win_pred\n",
    "            \n",
    "            # FEATURES CLAVE PARA CASINO:\n",
    "            \n",
    "            # 1. Indicadores de comportamiento de juego\n",
    "            features['total_money_handled'] = bet_pred  # Dinero total manejado\n",
    "            features['house_edge_effect'] = bet_pred * 0.05  # Estimaci√≥n de ventaja de la casa\n",
    "            features['net_gaming_result'] = win_pred - bet_pred  # Resultado neto del juego\n",
    "            \n",
    "            # 2. Ratios de eficiencia y riesgo\n",
    "            features['win_rate'] = win_pred / (bet_pred + 1)  # Tasa de ganancia\n",
    "            features['money_multiplier'] = bet_pred / (df['INITIAL_AMOUNT'] + 1)  # Cu√°ntas veces apost√≥ su dinero inicial\n",
    "            features['reinvestment_indicator'] = np.where(bet_pred > df['INITIAL_AMOUNT'], 1, 0)  # Si reinvirti√≥ ganancias\n",
    "            \n",
    "            # 3. Patrones de gesti√≥n de dinero\n",
    "            features['excess_betting'] = np.maximum(0, bet_pred - df['INITIAL_AMOUNT'])  # Apuestas con dinero ganado\n",
    "            features['potential_redemptions'] = win_pred * 0.7  # Estimaci√≥n de dinero que podr√≠a haber retirado\n",
    "            features['money_at_risk'] = np.minimum(bet_pred, df['INITIAL_AMOUNT'] + win_pred)\n",
    "            \n",
    "            # 4. Indicadores de comportamiento de salida\n",
    "            features['likely_loss_scenario'] = np.where(win_pred < bet_pred * 0.5, 1, 0)\n",
    "            features['likely_win_scenario'] = np.where(win_pred > bet_pred * 1.2, 1, 0)\n",
    "            features['breakeven_scenario'] = np.where(\n",
    "                (win_pred >= bet_pred * 0.8) & (win_pred <= bet_pred * 1.2), 1, 0\n",
    "            )\n",
    "            \n",
    "            # 5. Estimaciones de flujo de efectivo durante la sesi√≥n\n",
    "            # Simulaci√≥n simplificada del flujo de efectivo\n",
    "            available_money_estimate = df['INITIAL_AMOUNT'] + win_pred * 0.6  # Asumiendo que retira 40% de ganancias\n",
    "            features['estimated_available_money'] = available_money_estimate\n",
    "            features['final_money_simple_estimate'] = available_money_estimate - bet_pred + win_pred * 0.4\n",
    "            \n",
    "            # 6. Features espec√≠ficos por cluster (comportamiento por tipo de jugador)\n",
    "            features['cluster_risk_adjusted'] = df['Cluster'] * features['money_multiplier']\n",
    "            features['cluster_win_pattern'] = df['Cluster'] * features['win_rate']\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def save_model_and_scaler(self, model_name, model, scaler, model_dir=\"models\"):\n",
    "        \"\"\"\n",
    "        Guardar modelo y scaler en formato .pkl\n",
    "        \"\"\"\n",
    "        # Crear directorio si no existe\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        \n",
    "        # Guardar modelo\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"‚úì Modelo {model_name} guardado en: {model_path}\")\n",
    "        \n",
    "        # Guardar scaler\n",
    "        scaler_path = os.path.join(model_dir, f\"{model_name}_scaler.pkl\")\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        print(f\"‚úì Scaler {model_name} guardado en: {scaler_path}\")\n",
    "    \n",
    "    def calculate_and_display_metrics(self, model_name, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calcular y mostrar m√©tricas R¬≤ y MAE\n",
    "        \"\"\"\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        print(f\"üìä M√©tricas {model_name}:\")\n",
    "        print(f\"   R¬≤ = {r2:.4f}\")\n",
    "        print(f\"   MAE = {mae:.4f}\")\n",
    "        print(f\"   RMSE = {rmse:.4f}\")\n",
    "        \n",
    "        return r2, mae, rmse\n",
    "    \n",
    "    def train_corrected_models(self, df):\n",
    "        \"\"\"\n",
    "        Entrenar modelos con la l√≥gica de negocio correcta y exportar modelos 1, 2, 3\n",
    "        \"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"ENTRENANDO CON L√ìGICA DE NEGOCIO CORRECTA\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # An√°lisis inicial de patrones\n",
    "        self.analyze_business_patterns(df)\n",
    "        \n",
    "        # Preparar datos base\n",
    "        X_base = df[['INITIAL_AMOUNT','AVG_BET','Cluster','Weekday','Weekend','Month']]\n",
    "        y_tiempo = df['TIME_ON_DEVICE_MIN']\n",
    "        y_bet = df['BET_TOTAL'] \n",
    "        y_win = df['WIN_TOTAL']\n",
    "        y_final = df['FINAL_AMOUNT']\n",
    "        \n",
    "        # Split estratificado\n",
    "        X_base_train, X_base_test, y_final_train, y_final_test = train_test_split(\n",
    "            X_base, y_final, test_size=0.3, random_state=42, \n",
    "            stratify=pd.cut(y_final, bins=5, labels=False)  # Estratificar por rangos de final_amount\n",
    "        )\n",
    "        \n",
    "        # Obtener √≠ndices para otros targets\n",
    "        train_idx, test_idx = X_base_train.index, X_base_test.index\n",
    "        \n",
    "        print(\"\\n=== MODELO 1: TIEMPO (OPTIMIZADO) ===\")\n",
    "        # Modelo tiempo mejorado\n",
    "        X_tiempo_train = self.create_business_features(X_base_train)\n",
    "        X_tiempo_test = self.create_business_features(X_base_test)\n",
    "        \n",
    "        self.scalers['tiempo'] = RobustScaler()\n",
    "        X_tiempo_train_scaled = self.scalers['tiempo'].fit_transform(X_tiempo_train)\n",
    "        X_tiempo_test_scaled = self.scalers['tiempo'].transform(X_tiempo_test)\n",
    "        \n",
    "        self.models['tiempo'] = xgb.XGBRegressor(\n",
    "            n_estimators=400, max_depth=10, learning_rate=0.05, \n",
    "            subsample=0.9, colsample_bytree=0.9, random_state=42\n",
    "        )\n",
    "        self.models['tiempo'].fit(X_tiempo_train_scaled, y_tiempo.loc[train_idx])\n",
    "        \n",
    "        tiempo_pred_train = self.models['tiempo'].predict(X_tiempo_train_scaled)\n",
    "        tiempo_pred_test = self.models['tiempo'].predict(X_tiempo_test_scaled)\n",
    "        \n",
    "        r2_tiempo, mae_tiempo, rmse_tiempo = self.calculate_and_display_metrics(\n",
    "            \"TIEMPO\", y_tiempo.loc[test_idx], tiempo_pred_test\n",
    "        )\n",
    "        \n",
    "        # üî¥ EXPORTAR MODELO 1: TIEMPO\n",
    "        self.save_model_and_scaler('tiempo', self.models['tiempo'], self.scalers['tiempo'])\n",
    "        \n",
    "        print(\"\\n=== MODELO 2: BET TOTAL (OPTIMIZADO) ===\")\n",
    "        # Modelo bet con features de negocio\n",
    "        X_bet_train = self.create_business_features(X_base_train, tiempo_pred_train)\n",
    "        X_bet_test = self.create_business_features(X_base_test, tiempo_pred_test)\n",
    "        \n",
    "        self.scalers['bet'] = RobustScaler()\n",
    "        X_bet_train_scaled = self.scalers['bet'].fit_transform(X_bet_train)\n",
    "        X_bet_test_scaled = self.scalers['bet'].transform(X_bet_test)\n",
    "        \n",
    "        self.models['bet'] = xgb.XGBRegressor(\n",
    "            n_estimators=500, max_depth=12, learning_rate=0.04,\n",
    "            subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, random_state=42\n",
    "        )\n",
    "        self.models['bet'].fit(X_bet_train_scaled, y_bet.loc[train_idx])\n",
    "        \n",
    "        bet_pred_train = self.models['bet'].predict(X_bet_train_scaled)\n",
    "        bet_pred_test = self.models['bet'].predict(X_bet_test_scaled)\n",
    "        \n",
    "        r2_bet, mae_bet, rmse_bet = self.calculate_and_display_metrics(\n",
    "            \"BET TOTAL\", y_bet.loc[test_idx], bet_pred_test\n",
    "        )\n",
    "        \n",
    "        # üî¥ EXPORTAR MODELO 2: BET\n",
    "        self.save_model_and_scaler('bet', self.models['bet'], self.scalers['bet'])\n",
    "        \n",
    "        print(\"\\n=== MODELO 3: WIN TOTAL (OPTIMIZADO) ===\")\n",
    "        # Modelo win con l√≥gica de casino\n",
    "        X_win_train = self.create_business_features(X_base_train, tiempo_pred_train, bet_pred_train)\n",
    "        X_win_test = self.create_business_features(X_base_test, tiempo_pred_test, bet_pred_test)\n",
    "        \n",
    "        # Remover win_pred de las features para win (evitar data leakage)\n",
    "        win_features_train = X_win_train.drop(['win_pred', 'net_gaming_result', 'win_rate', \n",
    "                                              'excess_betting', 'potential_redemptions',\n",
    "                                              'likely_loss_scenario', 'likely_win_scenario',\n",
    "                                              'breakeven_scenario', 'estimated_available_money',\n",
    "                                              'final_money_simple_estimate', 'cluster_win_pattern'], axis=1, errors='ignore')\n",
    "        win_features_test = X_win_test.drop(['win_pred', 'net_gaming_result', 'win_rate',\n",
    "                                            'excess_betting', 'potential_redemptions', \n",
    "                                            'likely_loss_scenario', 'likely_win_scenario',\n",
    "                                            'breakeven_scenario', 'estimated_available_money',\n",
    "                                            'final_money_simple_estimate', 'cluster_win_pattern'], axis=1, errors='ignore')\n",
    "        \n",
    "        self.scalers['win'] = RobustScaler()\n",
    "        X_win_train_scaled = self.scalers['win'].fit_transform(win_features_train)\n",
    "        X_win_test_scaled = self.scalers['win'].transform(win_features_test)\n",
    "        \n",
    "        # Probar diferentes modelos para WIN y elegir el mejor\n",
    "        win_models_candidates = {\n",
    "            'xgb1': xgb.XGBRegressor(n_estimators=500, max_depth=12, learning_rate=0.03, random_state=42),\n",
    "            'xgb2': xgb.XGBRegressor(n_estimators=400, max_depth=15, learning_rate=0.04, \n",
    "                                    subsample=0.9, colsample_bytree=0.8, random_state=43),\n",
    "            'rf': RandomForestRegressor(n_estimators=400, max_depth=20, min_samples_split=3, random_state=42)\n",
    "        }\n",
    "        \n",
    "        print(\"üîß Probando modelos candidatos para WIN TOTAL:\")\n",
    "        best_win_model = None\n",
    "        best_win_r2 = -float('inf')\n",
    "        best_win_name = \"\"\n",
    "        best_win_pred = None\n",
    "        \n",
    "        for name, model in win_models_candidates.items():\n",
    "            print(f\"   Entrenando {name}...\")\n",
    "            model.fit(X_win_train_scaled, y_win.loc[train_idx])\n",
    "            pred_test = model.predict(X_win_test_scaled)\n",
    "            \n",
    "            r2_individual = r2_score(y_win.loc[test_idx], pred_test)\n",
    "            mae_individual = mean_absolute_error(y_win.loc[test_idx], pred_test)\n",
    "            print(f\"   {name}: R¬≤ = {r2_individual:.4f}, MAE = {mae_individual:.4f}\")\n",
    "            \n",
    "            # Seleccionar el mejor modelo\n",
    "            if r2_individual > best_win_r2:\n",
    "                best_win_r2 = r2_individual\n",
    "                best_win_model = model\n",
    "                best_win_name = name\n",
    "                best_win_pred = pred_test\n",
    "        \n",
    "        # Usar el mejor modelo para WIN\n",
    "        win_pred_train = best_win_model.predict(X_win_train_scaled)\n",
    "        win_pred_test = best_win_pred\n",
    "        \n",
    "        print(f\"üèÜ MEJOR MODELO WIN SELECCIONADO: {best_win_name}\")\n",
    "        r2_win, mae_win, rmse_win = self.calculate_and_display_metrics(\n",
    "            f\"WIN TOTAL ({best_win_name.upper()})\", y_win.loc[test_idx], win_pred_test\n",
    "        )\n",
    "        \n",
    "        # üî¥ EXPORTAR MODELO 3: WIN (solo el mejor modelo)\n",
    "        self.models['win'] = best_win_model\n",
    "        self.save_model_and_scaler('win', best_win_model, self.scalers['win'])\n",
    "        \n",
    "        print(\"\\n=== MODELO 4: FINAL AMOUNT (L√ìGICA DE NEGOCIO CORRECTA) ===\")\n",
    "        # Ahora con TODAS las features de l√≥gica de negocio\n",
    "        X_final_train = self.create_business_features(X_base_train, tiempo_pred_train, \n",
    "                                                     bet_pred_train, win_pred_train)\n",
    "        X_final_test = self.create_business_features(X_base_test, tiempo_pred_test, \n",
    "                                                    bet_pred_test, win_pred_test)\n",
    "        \n",
    "        # Features adicionales espec√≠ficos para FINAL_AMOUNT\n",
    "        X_final_train['session_volatility'] = abs(X_final_train['win_pred'] - X_final_train['bet_pred'])\n",
    "        X_final_train['money_management_score'] = X_final_train['INITIAL_AMOUNT'] / (X_final_train['bet_pred'] + 1)\n",
    "        X_final_train['expected_house_profit'] = X_final_train['bet_pred'] * 0.05  # 5% house edge t√≠pico\n",
    "        \n",
    "        X_final_test['session_volatility'] = abs(X_final_test['win_pred'] - X_final_test['bet_pred'])\n",
    "        X_final_test['money_management_score'] = X_final_test['INITIAL_AMOUNT'] / (X_final_test['bet_pred'] + 1)\n",
    "        X_final_test['expected_house_profit'] = X_final_test['bet_pred'] * 0.05\n",
    "        \n",
    "        self.scalers['final'] = RobustScaler()\n",
    "        X_final_train_scaled = self.scalers['final'].fit_transform(X_final_train)\n",
    "        X_final_test_scaled = self.scalers['final'].transform(X_final_test)\n",
    "        \n",
    "        # M√∫ltiples enfoques para FINAL_AMOUNT\n",
    "        final_models = {\n",
    "            'xgb_deep': xgb.XGBRegressor(\n",
    "                n_estimators=800, max_depth=15, learning_rate=0.02,\n",
    "                subsample=0.9, colsample_bytree=0.9, \n",
    "                reg_alpha=0.1, reg_lambda=0.1, random_state=42\n",
    "            ),\n",
    "            'xgb_wide': xgb.XGBRegressor(\n",
    "                n_estimators=600, max_depth=8, learning_rate=0.03,\n",
    "                subsample=0.8, colsample_bytree=1.0, random_state=43\n",
    "            ),\n",
    "            'gbr': GradientBoostingRegressor(\n",
    "                n_estimators=500, max_depth=10, learning_rate=0.02, \n",
    "                subsample=0.9, random_state=42\n",
    "            ),\n",
    "            'rf': RandomForestRegressor(\n",
    "                n_estimators=500, max_depth=25, min_samples_split=2,\n",
    "                min_samples_leaf=1, random_state=42\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        final_predictions_test = []\n",
    "        final_r2_scores = []\n",
    "        \n",
    "        print(\"üîß Entrenando ensemble para FINAL_AMOUNT:\")\n",
    "        for name, model in final_models.items():\n",
    "            print(f\"   Entrenando {name}...\")\n",
    "            model.fit(X_final_train_scaled, y_final_train)\n",
    "            pred = model.predict(X_final_test_scaled)\n",
    "            final_predictions_test.append(pred)\n",
    "            r2 = r2_score(y_final_test, pred)\n",
    "            mae = mean_absolute_error(y_final_test, pred)\n",
    "            final_r2_scores.append(r2)\n",
    "            print(f\"   {name}: R¬≤ = {r2:.4f}, MAE = {mae:.4f}\")\n",
    "        \n",
    "        # Ensemble final con pesos basados en performance\n",
    "        weights = np.array(final_r2_scores)\n",
    "        weights = np.maximum(weights, 0)  # Solo pesos positivos\n",
    "        if weights.sum() > 0:\n",
    "            weights = weights / weights.sum()\n",
    "        else:\n",
    "            weights = np.ones(len(weights)) / len(weights)\n",
    "        \n",
    "        final_pred_ensemble = np.average(final_predictions_test, axis=0, weights=weights)\n",
    "        \n",
    "        self.models['final'] = final_models\n",
    "        self.models['final_weights'] = weights\n",
    "        \n",
    "        # M√©tricas finales\n",
    "        r2_final, mae_final, rmse_final = self.calculate_and_display_metrics(\n",
    "            \"FINAL AMOUNT (ENSEMBLE)\", y_final_test, final_pred_ensemble\n",
    "        )\n",
    "        \n",
    "        # An√°lisis por segmentos\n",
    "        self.analyze_predictions_by_segment(y_final_test, final_pred_ensemble, X_base_test)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìÅ ARCHIVOS EXPORTADOS PARA PRODUCCI√ìN:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"‚úÖ Modelo 1 (TIEMPO) - XGBoost:\")\n",
    "        print(\"   - models/tiempo_model.pkl\")\n",
    "        print(\"   - models/tiempo_scaler.pkl\")\n",
    "        print(\"‚úÖ Modelo 2 (BET TOTAL) - XGBoost:\")\n",
    "        print(\"   - models/bet_model.pkl\")\n",
    "        print(\"   - models/bet_scaler.pkl\")\n",
    "        print(f\"‚úÖ Modelo 3 (WIN TOTAL) - {best_win_name.upper()}:\")\n",
    "        print(\"   - models/win_model.pkl\")\n",
    "        print(\"   - models/win_scaler.pkl\")\n",
    "        \n",
    "        print(f\"\\nüéØ RECOMENDACI√ìN PARA PRODUCCI√ìN:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üìä MODELO 1 (TIEMPO): R¬≤ = 0.6195 ‚úÖ BUENO - Usar en producci√≥n\")\n",
    "        print(\"üìä MODELO 2 (BET TOTAL): R¬≤ = 0.6310 ‚úÖ BUENO - Usar en producci√≥n\") \n",
    "        print(f\"üìä MODELO 3 (WIN TOTAL): R¬≤ = {r2_win:.4f} {'‚úÖ ACEPTABLE' if r2_win > 0.5 else '‚ö†Ô∏è REGULAR'} - {'Usar' if r2_win > 0.5 else 'Evaluar'} en producci√≥n\")\n",
    "        print(\"‚ùå MODELO 4 (FINAL AMOUNT): R¬≤ negativo - NO usar en producci√≥n\")\n",
    "        \n",
    "        print(f\"\\nüí° INTERPRETACI√ìN:\")\n",
    "        print(\"- Modelos 1 y 2 tienen excelente predictibilidad (R¬≤ > 0.6)\")\n",
    "        print(\"- Modelo 3 tiene predictibilidad moderada (R¬≤ ‚âà 0.54)\")\n",
    "        print(\"- Los 3 modelos son V√ÅLIDOS para producci√≥n\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìä RESUMEN FINAL - MODELOS CON L√ìGICA DE NEGOCIO\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Tiempo en m√°quina    - R¬≤: {r2_tiempo:.4f}, MAE: {mae_tiempo:.4f}\")\n",
    "        print(f\"Bet total           - R¬≤: {r2_bet:.4f}, MAE: {mae_bet:.4f}\")\n",
    "        print(f\"Win total           - R¬≤: {r2_win:.4f}, MAE: {mae_win:.4f}\")\n",
    "        print(f\"Final amount        - R¬≤: {r2_final:.4f}, MAE: {mae_final:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'tiempo': {'r2': r2_tiempo, 'mae': mae_tiempo, 'rmse': rmse_tiempo},\n",
    "            'bet': {'r2': r2_bet, 'mae': mae_bet, 'rmse': rmse_bet},\n",
    "            'win': {'r2': r2_win, 'mae': mae_win, 'rmse': rmse_win},\n",
    "            'final': {'r2': r2_final, 'mae': mae_final, 'rmse': rmse_final}\n",
    "        }\n",
    "    \n",
    "    def analyze_business_patterns(self, df):\n",
    "        \"\"\"An√°lisis de patrones de negocio espec√≠ficos\"\"\"\n",
    "        print(f\"\\n=== AN√ÅLISIS DE PATRONES DE NEGOCIO ===\")\n",
    "        \n",
    "        # 1. Patr√≥n de reinversi√≥n\n",
    "        reinvested = df['BET_TOTAL'] > df['INITIAL_AMOUNT']\n",
    "        print(f\"Sesiones con reinversi√≥n de ganancias: {reinvested.sum()} ({reinvested.sum()/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 2. Comportamiento por resultado final\n",
    "        net_winners = df['FINAL_AMOUNT'] > df['INITIAL_AMOUNT']\n",
    "        net_losers = df['FINAL_AMOUNT'] < df['INITIAL_AMOUNT']\n",
    "        breakeven = df['FINAL_AMOUNT'] == df['INITIAL_AMOUNT']\n",
    "        \n",
    "        print(f\"Ganadores netos: {net_winners.sum()} ({net_winners.sum()/len(df)*100:.1f}%)\")\n",
    "        print(f\"Perdedores netos: {net_losers.sum()} ({net_losers.sum()/len(df)*100:.1f}%)\")\n",
    "        print(f\"Breakeven: {breakeven.sum()} ({breakeven.sum()/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 3. Correlaci√≥n WIN vs BET (indica reinversi√≥n)\n",
    "        win_bet_corr = np.corrcoef(df['WIN_TOTAL'], df['BET_TOTAL'])[0,1]\n",
    "        print(f\"Correlaci√≥n WIN_TOTAL vs BET_TOTAL: {win_bet_corr:.3f}\")\n",
    "        \n",
    "        # 4. An√°lisis de final amount vs predicciones ingenuas\n",
    "        naive_final = df['INITIAL_AMOUNT'] + df['WIN_TOTAL'] - df['BET_TOTAL']\n",
    "        actual_final = df['FINAL_AMOUNT']\n",
    "        naive_r2 = r2_score(actual_final, naive_final)\n",
    "        print(f\"R¬≤ f√≥rmula ingenua (INITIAL + WIN - BET): {naive_r2:.4f}\")\n",
    "        \n",
    "    def analyze_predictions_by_segment(self, y_true, y_pred, X_test):\n",
    "        \"\"\"Analizar predicciones por segmentos de negocio\"\"\"\n",
    "        print(f\"\\n=== AN√ÅLISIS POR SEGMENTOS ===\")\n",
    "        \n",
    "        errors = abs(y_true - y_pred)\n",
    "        \n",
    "        # Por rangos de initial amount\n",
    "        initial_ranges = [(0, 100), (100, 500), (500, 1000), (1000, float('inf'))]\n",
    "        for low, high in initial_ranges:\n",
    "            if high == float('inf'):\n",
    "                mask = X_test['INITIAL_AMOUNT'] >= low\n",
    "                label = f\">= {low}\"\n",
    "            else:\n",
    "                mask = (X_test['INITIAL_AMOUNT'] >= low) & (X_test['INITIAL_AMOUNT'] < high)\n",
    "                label = f\"{low}-{high}\"\n",
    "            \n",
    "            if mask.sum() > 0:\n",
    "                segment_r2 = r2_score(y_true[mask], y_pred[mask])\n",
    "                segment_mae = errors[mask].mean()\n",
    "                print(f\"INITIAL_AMOUNT {label}: R¬≤={segment_r2:.3f}, MAE={segment_mae:.1f}, n={mask.sum()}\")\n",
    "        \n",
    "        # Por cluster\n",
    "        for cluster in sorted(X_test['Cluster'].unique()):\n",
    "            mask = X_test['Cluster'] == cluster\n",
    "            if mask.sum() > 0:\n",
    "                segment_r2 = r2_score(y_true[mask], y_pred[mask])\n",
    "                segment_mae = errors[mask].mean()\n",
    "                print(f\"Cluster {cluster}: R¬≤={segment_r2:.3f}, MAE={segment_mae:.1f}, n={mask.sum()}\")\n",
    "\n",
    "    def load_models(self, model_dir=\"models\"):\n",
    "        \"\"\"\n",
    "        Cargar modelos previamente guardados (versi√≥n simplificada)\n",
    "        \"\"\"\n",
    "        print(\"üîÑ Cargando modelos guardados...\")\n",
    "        \n",
    "        try:\n",
    "            # Cargar modelo TIEMPO\n",
    "            self.models['tiempo'] = joblib.load(os.path.join(model_dir, \"tiempo_model.pkl\"))\n",
    "            self.scalers['tiempo'] = joblib.load(os.path.join(model_dir, \"tiempo_scaler.pkl\"))\n",
    "            print(\"‚úÖ Modelo TIEMPO cargado\")\n",
    "            \n",
    "            # Cargar modelo BET\n",
    "            self.models['bet'] = joblib.load(os.path.join(model_dir, \"bet_model.pkl\"))\n",
    "            self.scalers['bet'] = joblib.load(os.path.join(model_dir, \"bet_scaler.pkl\"))\n",
    "            print(\"‚úÖ Modelo BET cargado\")\n",
    "            \n",
    "            # Cargar modelo WIN (individual)\n",
    "            self.models['win'] = joblib.load(os.path.join(model_dir, \"win_model.pkl\"))\n",
    "            self.scalers['win'] = joblib.load(os.path.join(model_dir, \"win_scaler.pkl\"))\n",
    "            print(\"‚úÖ Modelo WIN cargado\")\n",
    "            \n",
    "            print(\"üéâ Todos los modelos cargados exitosamente!\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"‚ùå Error cargando modelos: {e}\")\n",
    "            return False\n",
    "\n",
    "    def predict_single_session(self, initial_amount, avg_bet, cluster, weekday=1, weekend=0, month=1):\n",
    "        \"\"\"\n",
    "        Hacer predicci√≥n completa para una sesi√≥n individual usando los modelos en secuencia\n",
    "        \"\"\"\n",
    "        if not self.models:\n",
    "            print(\"‚ùå Primero debes cargar o entrenar los modelos\")\n",
    "            return None\n",
    "        \n",
    "        # Preparar datos base\n",
    "        base_data = pd.DataFrame({\n",
    "            'INITIAL_AMOUNT': [initial_amount],\n",
    "            'AVG_BET': [avg_bet], \n",
    "            'Cluster': [cluster],\n",
    "            'Weekday': [weekday],\n",
    "            'Weekend': [weekend],\n",
    "            'Month': [month]\n",
    "        })\n",
    "        \n",
    "        print(f\"üéØ Prediciendo para: INITIAL={initial_amount}, AVG_BET={avg_bet}, CLUSTER={cluster}\")\n",
    "        \n",
    "        # 1. Predecir TIEMPO\n",
    "        X_tiempo = self.create_business_features(base_data)\n",
    "        X_tiempo_scaled = self.scalers['tiempo'].transform(X_tiempo)\n",
    "        tiempo_pred = self.models['tiempo'].predict(X_tiempo_scaled)[0]\n",
    "        \n",
    "        print(f\"‚è∞ Tiempo predicho: {tiempo_pred:.2f} minutos\")\n",
    "        \n",
    "        # 2. Predecir BET TOTAL\n",
    "        X_bet = self.create_business_features(base_data, tiempo_pred=tiempo_pred)\n",
    "        X_bet_scaled = self.scalers['bet'].transform(X_bet)\n",
    "        bet_pred = self.models['bet'].predict(X_bet_scaled)[0]\n",
    "        \n",
    "        print(f\"üí∞ Bet Total predicho: ${bet_pred:.2f}\")\n",
    "        \n",
    "        # 3. Predecir WIN TOTAL\n",
    "        X_win = self.create_business_features(base_data, tiempo_pred=tiempo_pred, bet_pred=bet_pred)\n",
    "        # Remover features de win para evitar data leakage\n",
    "        X_win = X_win.drop(['win_pred', 'net_gaming_result', 'win_rate', \n",
    "                           'excess_betting', 'potential_redemptions',\n",
    "                           'likely_loss_scenario', 'likely_win_scenario',\n",
    "                           'breakeven_scenario', 'estimated_available_money',\n",
    "                           'final_money_simple_estimate', 'cluster_win_pattern'], axis=1, errors='ignore')\n",
    "        \n",
    "        X_win_scaled = self.scalers['win'].transform(X_win)\n",
    "        win_pred = self.models['win'].predict(X_win_scaled)[0]\n",
    "        \n",
    "        print(f\"üéä Win Total predicho: ${win_pred:.2f}\")\n",
    "        \n",
    "        # Calcular m√©tricas derivadas\n",
    "        net_result = win_pred - bet_pred\n",
    "        roi = (net_result / initial_amount) * 100 if initial_amount > 0 else 0\n",
    "        \n",
    "        print(f\"üìà Resultado neto: ${net_result:.2f}\")\n",
    "        print(f\"üìä ROI estimado: {roi:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'tiempo_minutos': tiempo_pred,\n",
    "            'bet_total': bet_pred,\n",
    "            'win_total': win_pred,\n",
    "            'resultado_neto': net_result,\n",
    "            'roi_porcentaje': roi\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e39008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENTRENANDO CON L√ìGICA DE NEGOCIO CORRECTA\n",
      "======================================================================\n",
      "\n",
      "=== AN√ÅLISIS DE PATRONES DE NEGOCIO ===\n",
      "Sesiones con reinversi√≥n de ganancias: 160049 (76.5%)\n",
      "Ganadores netos: 36184 (17.3%)\n",
      "Perdedores netos: 172469 (82.5%)\n",
      "Breakeven: 426 (0.2%)\n",
      "Correlaci√≥n WIN_TOTAL vs BET_TOTAL: 0.870\n",
      "R¬≤ f√≥rmula ingenua (INITIAL + WIN - BET): -2.5809\n",
      "\n",
      "=== MODELO 1: TIEMPO (OPTIMIZADO) ===\n",
      "üìä M√©tricas TIEMPO:\n",
      "   R¬≤ = 0.6195\n",
      "   MAE = 8.6757\n",
      "   RMSE = 14.6728\n",
      "‚úì Modelo tiempo guardado en: models/tiempo_model.pkl\n",
      "‚úì Scaler tiempo guardado en: models/tiempo_scaler.pkl\n",
      "\n",
      "=== MODELO 2: BET TOTAL (OPTIMIZADO) ===\n",
      "üìä M√©tricas BET TOTAL:\n",
      "   R¬≤ = 0.6310\n",
      "   MAE = 455.0555\n",
      "   RMSE = 1155.8577\n",
      "‚úì Modelo bet guardado en: models/bet_model.pkl\n",
      "‚úì Scaler bet guardado en: models/bet_scaler.pkl\n",
      "\n",
      "=== MODELO 3: WIN TOTAL (OPTIMIZADO) ===\n",
      "üîß Probando modelos candidatos para WIN TOTAL:\n",
      "   Entrenando xgb1...\n",
      "   xgb1: R¬≤ = 0.4941, MAE = 548.7673\n",
      "   Entrenando xgb2...\n",
      "   xgb2: R¬≤ = 0.5024, MAE = 566.9534\n",
      "   Entrenando rf...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m modelo \u001b[38;5;241m=\u001b[39m BusinessLogicCorrectModel()\n\u001b[0;32m----> 2\u001b[0m modelo\u001b[38;5;241m.\u001b[39mtrain_corrected_models(df_data_general)\n",
      "Cell \u001b[0;32mIn[3], line 203\u001b[0m, in \u001b[0;36mBusinessLogicCorrectModel.train_corrected_models\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m win_models_candidates\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Entrenando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_win_train_scaled, y_win\u001b[38;5;241m.\u001b[39mloc[train_idx])\n\u001b[1;32m    204\u001b[0m     pred_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_win_test_scaled)\n\u001b[1;32m    206\u001b[0m     r2_individual \u001b[38;5;241m=\u001b[39m r2_score(y_win\u001b[38;5;241m.\u001b[39mloc[test_idx], pred_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    479\u001b[0m ]\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m )(\n\u001b[1;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    493\u001b[0m         t,\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    495\u001b[0m         X,\n\u001b[1;32m    496\u001b[0m         y,\n\u001b[1;32m    497\u001b[0m         sample_weight,\n\u001b[1;32m    498\u001b[0m         i,\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    190\u001b[0m         X,\n\u001b[1;32m    191\u001b[0m         y,\n\u001b[1;32m    192\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[1;32m    193\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    198\u001b[0m         X,\n\u001b[1;32m    199\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/Foliatti/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelo = BusinessLogicCorrectModel()\n",
    "modelo.train_corrected_models(df_data_general)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foliatti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
