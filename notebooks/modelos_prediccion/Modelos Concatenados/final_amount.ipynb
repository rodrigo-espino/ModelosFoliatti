{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bc459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "import joblib\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85be778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_general = pd.read_csv('../../../data/data_general.csv')\n",
    "\n",
    "df_data_general['INITIAL_TIME'] = pd.to_datetime(df_data_general['INITIAL_TIME'])\n",
    "df_data_general['FINAL_TIME'] = pd.to_datetime(df_data_general['FINAL_TIME'])\n",
    "\n",
    "df_data_general['INITIAL_TIME'] = df_data_general['INITIAL_TIME'].dt.to_period('D')\n",
    "df_data_general['INITIAL_TIME'] = df_data_general['INITIAL_TIME'].dt.to_timestamp()\n",
    "\n",
    "\n",
    "df_data_general['FINAL_TIME'] = df_data_general['FINAL_TIME'].dt.to_period('D')\n",
    "df_data_general['FINAL_TIME'] = df_data_general['FINAL_TIME'].dt.to_timestamp()\n",
    "\n",
    "df_data_general['Weekday']= df_data_general['INITIAL_TIME'].dt.strftime('%A')\n",
    "df_data_general['number_of_day'] = df_data_general['INITIAL_TIME'].dt.day_of_week\n",
    "\n",
    "df_data_general['TIME_ON_DEVICE_MIN'] = df_data_general['TIME_ON_DEVICE_SEC'] / 60\n",
    "\n",
    "df_data_general['Hour'] = df_data_general['INITIAL_TIME'].dt.hour\n",
    "df_data_general['Weekday'] = df_data_general['INITIAL_TIME'].dt.weekday   # 0=Lunes, 6=Domingo\n",
    "df_data_general['Weekend'] = (df_data_general['Weekday'] >= 5).astype(int)\n",
    "df_data_general['Month'] = df_data_general['INITIAL_TIME'].dt.month\n",
    "\n",
    "df_data_general = df_data_general[df_data_general['TIME_ON_DEVICE_MIN'] < 600 ]\n",
    "\n",
    "df_data_general = df_data_general[df_data_general['WIN_TOTAL'] > 0]\n",
    "df_data_general['NET_SPEND'] = df_data_general['FINAL_AMOUNT'] - df_data_general['INITIAL_AMOUNT']\n",
    "df_data_general = df_data_general[df_data_general['NET_SPEND'] < 10000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822bb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_general['CASINO_WON'] = df_data_general['NET_SPEND'] <  df_data_general['INITIAL_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc456cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ensemble Model listo para usar!\n",
      "üìñ Lee las instrucciones en los comentarios para comenzar.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CasinoEnsembleModelOptimized:\n",
    "    def __init__(self, model_paths):\n",
    "        \"\"\"\n",
    "        Inicializa el modelo ensemble cargando los modelos pre-entrenados\n",
    "        \n",
    "        Args:\n",
    "            model_paths (dict): Diccionario con las rutas de los modelos y scalers\n",
    "        \"\"\"\n",
    "        self.model_paths = model_paths\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.ensemble_scaler = StandardScaler()\n",
    "        self.trained_classifiers = {}\n",
    "        \n",
    "        # Cargar modelos pre-entrenados\n",
    "        self.load_pretrained_models()\n",
    "    \n",
    "    def load_pretrained_models(self):\n",
    "        \"\"\"Carga los modelos y scalers pre-entrenados\"\"\"\n",
    "        try:\n",
    "            # Cargar modelos de Keras\n",
    "            self.models['time'] = load_model(self.model_paths['tiempo_model'])\n",
    "            self.models['bet'] = load_model(self.model_paths['bet_model'])\n",
    "            self.models['win'] = load_model(self.model_paths['win_model'])\n",
    "            \n",
    "            # Cargar scalers con joblib\n",
    "            self.scalers['time'] = joblib.load(self.model_paths['tiempo_scaler'])\n",
    "            self.scalers['bet'] = joblib.load(self.model_paths['bet_scaler'])\n",
    "            self.scalers['win'] = joblib.load(self.model_paths['win_scaler'])\n",
    "            \n",
    "            print(\"‚úÖ Todos los modelos y scalers cargados correctamente\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cargando modelos: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_business_features(self, base_data, tiempo_pred=None, bet_pred=None):\n",
    "        \"\"\"\n",
    "        Crea las features de negocio necesarias para los modelos (ID√âNTICA a tu CasinoMLPModel)\n",
    "        \"\"\"\n",
    "        features = base_data[['INITIAL_AMOUNT', 'AVG_BET', 'Cluster']].copy()\n",
    "        \n",
    "        if tiempo_pred is not None:\n",
    "            features['tiempo_pred'] = tiempo_pred\n",
    "            \n",
    "        if bet_pred is not None:\n",
    "            features['bet_pred'] = bet_pred\n",
    "            features['total_money_handled'] = bet_pred\n",
    "            features['house_edge_effect'] = bet_pred * 0.05\n",
    "            features['money_multiplier'] = bet_pred / (base_data['INITIAL_AMOUNT'] + 1)\n",
    "            features['reinvestment_indicator'] = np.where(bet_pred > base_data['INITIAL_AMOUNT'], 1, 0)\n",
    "            features['excess_betting'] = np.maximum(0, bet_pred - base_data['INITIAL_AMOUNT'])\n",
    "            features['money_at_risk'] = np.minimum(bet_pred, base_data['INITIAL_AMOUNT'])\n",
    "            features['cluster_risk_adjusted'] = base_data['Cluster'] * features['money_multiplier']\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def predict_session(self, initial_amount, avg_bet, cluster, weekday=1, weekend=0, month=1):\n",
    "        \"\"\"\n",
    "        Hacer predicci√≥n completa para una sesi√≥n usando los modelos MLP en secuencia\n",
    "        \"\"\"\n",
    "        if not self.models:\n",
    "            return {\"error\": \"Modelos no cargados correctamente\"}\n",
    "        \n",
    "        # Preparar datos base\n",
    "        base_data = pd.DataFrame({\n",
    "            'INITIAL_AMOUNT': [initial_amount],\n",
    "            'AVG_BET': [avg_bet], \n",
    "            'Cluster': [cluster],\n",
    "            'Weekday': [weekday],\n",
    "            'Weekend': [weekend],\n",
    "            'Month': [month]\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            results = {}\n",
    "            \n",
    "            # 1. Predecir TIEMPO\n",
    "            if 'time' in self.models:\n",
    "                try:\n",
    "                    X_tiempo = self.create_business_features(base_data)\n",
    "                    X_tiempo_scaled = self.scalers['time'].transform(X_tiempo)\n",
    "                    tiempo_pred = float(self.models['time'].predict(X_tiempo_scaled, verbose=0)[0][0])\n",
    "                    tiempo_pred = max(0, tiempo_pred)  # Asegurar valor positivo\n",
    "                    results['time_on_device'] = tiempo_pred\n",
    "                except Exception as e:\n",
    "                    print(f\"Error prediciendo tiempo: {e}\")\n",
    "                    tiempo_pred = 30.0\n",
    "                    results['time_on_device'] = tiempo_pred\n",
    "            else:\n",
    "                tiempo_pred = 30.0\n",
    "                results['time_on_device'] = tiempo_pred\n",
    "            \n",
    "            # 2. Predecir BET TOTAL\n",
    "            if 'bet' in self.models:\n",
    "                try:\n",
    "                    X_bet = self.create_business_features(base_data, tiempo_pred=tiempo_pred)\n",
    "                    X_bet_scaled = self.scalers['bet'].transform(X_bet)\n",
    "                    bet_pred = float(self.models['bet'].predict(X_bet_scaled, verbose=0)[0][0])\n",
    "                    bet_pred = max(0, bet_pred)  # Asegurar valor positivo\n",
    "                    results['bet_total'] = bet_pred\n",
    "                except Exception as e:\n",
    "                    print(f\"Error prediciendo bet: {e}\")\n",
    "                    bet_pred = initial_amount * 2\n",
    "                    results['bet_total'] = bet_pred\n",
    "            else:\n",
    "                bet_pred = initial_amount * 2\n",
    "                results['bet_total'] = bet_pred\n",
    "            \n",
    "            # 3. Predecir WIN TOTAL\n",
    "            if 'win' in self.models:\n",
    "                try:\n",
    "                    X_win = self.create_business_features(base_data, tiempo_pred=tiempo_pred, bet_pred=bet_pred)\n",
    "                    X_win_scaled = self.scalers['win'].transform(X_win)\n",
    "                    win_pred = float(self.models['win'].predict(X_win_scaled, verbose=0)[0][0])\n",
    "                    win_pred = max(0, win_pred)  # Asegurar valor positivo\n",
    "                    results['win_total'] = win_pred\n",
    "                except Exception as e:\n",
    "                    print(f\"Error prediciendo win: {e}\")\n",
    "                    win_pred = bet_pred * 0.95\n",
    "                    results['win_total'] = win_pred\n",
    "            else:\n",
    "                win_pred = bet_pred * 0.95\n",
    "                results['win_total'] = win_pred\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error en predicci√≥n: {str(e)}\"}\n",
    "    \n",
    "    def generate_ensemble_features_batch(self, input_data, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Versi√≥n OPTIMIZADA que procesa en lotes para mejor rendimiento\n",
    "        \"\"\"\n",
    "        ensemble_features = []\n",
    "        total_batches = len(input_data) // batch_size + (1 if len(input_data) % batch_size > 0 else 1)\n",
    "        \n",
    "        print(f\"üîÑ Procesando {len(input_data)} sesiones en {total_batches} lotes de {batch_size}...\")\n",
    "        \n",
    "        for batch_idx in range(0, len(input_data), batch_size):\n",
    "            batch_end = min(batch_idx + batch_size, len(input_data))\n",
    "            batch_data = input_data.iloc[batch_idx:batch_end]\n",
    "            \n",
    "            current_batch = (batch_idx // batch_size) + 1\n",
    "            print(f\"üì¶ Procesando lote {current_batch}/{total_batches} ({len(batch_data)} sesiones)...\")\n",
    "            \n",
    "            # Procesar tiempo en batch\n",
    "            X_tiempo_batch = []\n",
    "            for _, row in batch_data.iterrows():\n",
    "                base_data = pd.DataFrame({\n",
    "                    'INITIAL_AMOUNT': [row['INITIAL_AMOUNT']],\n",
    "                    'AVG_BET': [row['AVG_BET']],\n",
    "                    'Cluster': [row['Cluster']]\n",
    "                })\n",
    "                X_tiempo = self.create_business_features(base_data)\n",
    "                X_tiempo_batch.append(X_tiempo.iloc[0].values)\n",
    "            \n",
    "            X_tiempo_batch = np.array(X_tiempo_batch)\n",
    "            X_tiempo_scaled = self.scalers['time'].transform(X_tiempo_batch)\n",
    "            tiempo_preds = self.models['time'].predict(X_tiempo_scaled, verbose=0).flatten()\n",
    "            tiempo_preds = np.maximum(0, tiempo_preds)\n",
    "            \n",
    "            # Procesar bet en batch\n",
    "            X_bet_batch = []\n",
    "            for i, (_, row) in enumerate(batch_data.iterrows()):\n",
    "                base_data = pd.DataFrame({\n",
    "                    'INITIAL_AMOUNT': [row['INITIAL_AMOUNT']],\n",
    "                    'AVG_BET': [row['AVG_BET']],\n",
    "                    'Cluster': [row['Cluster']]\n",
    "                })\n",
    "                X_bet = self.create_business_features(base_data, tiempo_pred=tiempo_preds[i])\n",
    "                X_bet_batch.append(X_bet.iloc[0].values)\n",
    "            \n",
    "            X_bet_batch = np.array(X_bet_batch)\n",
    "            X_bet_scaled = self.scalers['bet'].transform(X_bet_batch)\n",
    "            bet_preds = self.models['bet'].predict(X_bet_scaled, verbose=0).flatten()\n",
    "            bet_preds = np.maximum(0, bet_preds)\n",
    "            \n",
    "            # Procesar win en batch\n",
    "            X_win_batch = []\n",
    "            for i, (_, row) in enumerate(batch_data.iterrows()):\n",
    "                base_data = pd.DataFrame({\n",
    "                    'INITIAL_AMOUNT': [row['INITIAL_AMOUNT']],\n",
    "                    'AVG_BET': [row['AVG_BET']],\n",
    "                    'Cluster': [row['Cluster']]\n",
    "                })\n",
    "                X_win = self.create_business_features(base_data, tiempo_pred=tiempo_preds[i], bet_pred=bet_preds[i])\n",
    "                X_win_batch.append(X_win.iloc[0].values)\n",
    "            \n",
    "            X_win_batch = np.array(X_win_batch)\n",
    "            X_win_scaled = self.scalers['win'].transform(X_win_batch)\n",
    "            win_preds = self.models['win'].predict(X_win_scaled, verbose=0).flatten()\n",
    "            win_preds = np.maximum(0, win_preds)\n",
    "            \n",
    "            # Crear features del ensemble para este batch\n",
    "            for i, (_, row) in enumerate(batch_data.iterrows()):\n",
    "                feature_vector = {\n",
    "                    'time_on_device': tiempo_preds[i],\n",
    "                    'bet_total': bet_preds[i],\n",
    "                    'win_total': win_preds[i],\n",
    "                    'initial_amount': row['INITIAL_AMOUNT'],\n",
    "                    'cluster': row['Cluster'],\n",
    "                    'avg_bet': row['AVG_BET']\n",
    "                }\n",
    "                ensemble_features.append(feature_vector)\n",
    "            \n",
    "            # Progreso\n",
    "            progress = min(((batch_idx + batch_size) / len(input_data)) * 100, 100)\n",
    "            print(f\"‚úÖ Lote {current_batch} completado. Progreso: {progress:.1f}%\")\n",
    "        \n",
    "        result_df = pd.DataFrame(ensemble_features)\n",
    "        \n",
    "        print(f\"‚úÖ Features del ensemble generadas exitosamente:\")\n",
    "        print(f\"   - {len(result_df)} sesiones procesadas\")\n",
    "        print(f\"   - Variables generadas por modelos MLP: time_on_device, bet_total, win_total\")\n",
    "        print(f\"   - Variables originales: initial_amount, cluster, avg_bet\")\n",
    "        print(f\"   - Total features para clasificaci√≥n: {result_df.shape[1]}\")\n",
    "        \n",
    "        # Mostrar estad√≠sticas de las predicciones generadas\n",
    "        print(f\"\\nüìä Estad√≠sticas de predicciones generadas:\")\n",
    "        print(f\"   time_on_device: {result_df['time_on_device'].mean():.2f} ¬± {result_df['time_on_device'].std():.2f}\")\n",
    "        print(f\"   bet_total: ${result_df['bet_total'].mean():.2f} ¬± ${result_df['bet_total'].std():.2f}\")\n",
    "        print(f\"   win_total: ${result_df['win_total'].mean():.2f} ¬± ${result_df['win_total'].std():.2f}\")\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def generate_ensemble_features(self, input_data):\n",
    "        \"\"\"\n",
    "        Wrapper que usa la versi√≥n batch optimizada\n",
    "        \"\"\"\n",
    "        return self.generate_ensemble_features_batch(input_data, batch_size=1000)\n",
    "    \n",
    "    def prepare_ensemble_features(self, data, target_col='CASINO_WON'):\n",
    "        \"\"\"\n",
    "        Prepara las features para el modelo ensemble usando predicciones batch\n",
    "        \"\"\"\n",
    "        # Verificar que tenemos las features base necesarias\n",
    "        required_base_features = ['INITIAL_AMOUNT', 'AVG_BET', 'Cluster']\n",
    "        missing_base = [f for f in required_base_features if f not in data.columns]\n",
    "        if missing_base:\n",
    "            raise ValueError(f\"Features base faltantes para generar predicciones: {missing_base}\")\n",
    "        \n",
    "        # Verificar que tenemos la columna objetivo\n",
    "        if target_col not in data.columns:\n",
    "            raise ValueError(f\"Columna objetivo '{target_col}' no encontrada\")\n",
    "        \n",
    "        print(\"üîÑ Generando predicciones usando modelos individuales (procesamiento batch)...\")\n",
    "        X = self.generate_ensemble_features(data)\n",
    "        y = data[target_col].iloc[:len(X)]  # Asegurar mismo length en caso de filas fallidas\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train_ensemble_models_sampled(self, data, target_col='CASINO_WON', sample_size=10000, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Entrena usando una muestra estratificada para acelerar el proceso\n",
    "        \"\"\"\n",
    "        print(f\"üéØ Usando muestreo estratificado de {sample_size} sesiones de {len(data)} totales\")\n",
    "        \n",
    "        # Separar por clase\n",
    "        class_0 = data[data[target_col] == 0]\n",
    "        class_1 = data[data[target_col] == 1]\n",
    "        \n",
    "        print(f\"üìä Distribuci√≥n original:\")\n",
    "        print(f\"   Clase 0 (Jugador gana): {len(class_0)} ({len(class_0)/len(data)*100:.1f}%)\")\n",
    "        print(f\"   Clase 1 (Casino gana): {len(class_1)} ({len(class_1)/len(data)*100:.1f}%)\")\n",
    "        \n",
    "        # Calcular muestras por clase manteniendo la proporci√≥n\n",
    "        proportion_class_1 = len(class_1) / len(data)\n",
    "        n_class_1 = min(len(class_1), int(sample_size * proportion_class_1))\n",
    "        n_class_0 = min(len(class_0), sample_size - n_class_1)\n",
    "        \n",
    "        # Ajustar si no hay suficientes datos de alguna clase\n",
    "        if n_class_0 + n_class_1 < sample_size:\n",
    "            print(f\"‚ö†Ô∏è Ajustando tama√±o de muestra a {n_class_0 + n_class_1} (datos disponibles)\")\n",
    "            sample_size = n_class_0 + n_class_1\n",
    "        \n",
    "        # Muestrear\n",
    "        sampled_class_0 = resample(class_0, n_samples=n_class_0, random_state=42, replace=False)\n",
    "        sampled_class_1 = resample(class_1, n_samples=n_class_1, random_state=42, replace=False)\n",
    "        \n",
    "        sampled_data = pd.concat([sampled_class_0, sampled_class_1]).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"üìä Muestra seleccionada: {len(sampled_data)} sesiones\")\n",
    "        print(f\"   Distribuci√≥n muestreada:\")\n",
    "        print(f\"   Clase 0: {len(sampled_class_0)} ({len(sampled_class_0)/len(sampled_data)*100:.1f}%)\")\n",
    "        print(f\"   Clase 1: {len(sampled_class_1)} ({len(sampled_class_1)/len(sampled_data)*100:.1f}%)\")\n",
    "        \n",
    "        # Entrenar con la muestra\n",
    "        return self.train_ensemble_models(sampled_data, target_col, test_size)\n",
    "    \n",
    "    def train_knn_model(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Entrena y eval√∫a modelo KNN\"\"\"\n",
    "        print(\"\\nüîπ Entrenando modelo KNN...\")\n",
    "        \n",
    "        # Grid search para encontrar mejores par√°metros\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan']\n",
    "        }\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "        grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_knn = grid_search.best_estimator_\n",
    "        self.trained_classifiers['KNN'] = best_knn\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = best_knn.predict(X_test)\n",
    "        y_proba = best_knn.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # M√©tricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc_score = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        print(f\"Mejores par√°metros: {grid_search.best_params_}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_score:.4f}\")\n",
    "        print(\"\\nReporte de clasificaci√≥n:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return {\n",
    "            'model': best_knn,\n",
    "            'accuracy': accuracy,\n",
    "            'auc_score': auc_score,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_proba\n",
    "        }\n",
    "    \n",
    "    def train_random_forest_model(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Entrena y eval√∫a modelo Random Forest\"\"\"\n",
    "        print(\"\\nüå≥ Entrenando modelo Random Forest...\")\n",
    "        \n",
    "        # Par√°metros para Random Forest\n",
    "        param_grid = {\n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "        grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_rf = grid_search.best_estimator_\n",
    "        self.trained_classifiers['RandomForest'] = best_rf\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "        y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # M√©tricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc_score = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        print(f\"Mejores par√°metros: {grid_search.best_params_}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_score:.4f}\")\n",
    "        \n",
    "        # Importancia de features\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': best_rf.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nImportancia de features:\")\n",
    "        print(feature_importance)\n",
    "        print(\"\\nReporte de clasificaci√≥n:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return {\n",
    "            'model': best_rf,\n",
    "            'accuracy': accuracy,\n",
    "            'auc_score': auc_score,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_proba,\n",
    "            'feature_importance': feature_importance\n",
    "        }\n",
    "    \n",
    "    def train_mlp_model(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Entrena y eval√∫a modelo MLP\"\"\"\n",
    "        print(\"\\nüß† Entrenando modelo MLP...\")\n",
    "        \n",
    "        # Par√°metros para MLP\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "            'alpha': [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "        \n",
    "        mlp = MLPClassifier(random_state=42, max_iter=1000)\n",
    "        grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_mlp = grid_search.best_estimator_\n",
    "        self.trained_classifiers['MLP'] = best_mlp\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = best_mlp.predict(X_test)\n",
    "        y_proba = best_mlp.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # M√©tricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc_score = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        print(f\"Mejores par√°metros: {grid_search.best_params_}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_score:.4f}\")\n",
    "        print(\"\\nReporte de clasificaci√≥n:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return {\n",
    "            'model': best_mlp,\n",
    "            'accuracy': accuracy,\n",
    "            'auc_score': auc_score,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_proba\n",
    "        }\n",
    "    \n",
    "    def train_ensemble_models(self, data, target_col='CASINO_WON', test_size=0.2):\n",
    "        \"\"\"\n",
    "        Entrena todos los modelos ensemble usando las predicciones de los modelos individuales\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Iniciando entrenamiento de modelos ensemble...\")\n",
    "        print(\"üìù Las features time_on_device, bet_total, win_total se generar√°n desde los modelos pre-entrenados\")\n",
    "        \n",
    "        # Verificar columnas requeridas\n",
    "        required_cols = ['INITIAL_AMOUNT', 'AVG_BET', 'Cluster', target_col]\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Columnas requeridas faltantes: {missing_cols}\")\n",
    "        \n",
    "        print(f\"üìã Columnas disponibles: {list(data.columns)}\")\n",
    "        print(f\"üìä Dataset shape: {data.shape}\")\n",
    "        \n",
    "        # Preparar features (genera predicciones desde modelos MLP usando batch processing)\n",
    "        X, y = self.prepare_ensemble_features(data, target_col)\n",
    "        \n",
    "        print(f\"üìä Datos preparados: {X.shape[0]} muestras, {X.shape[1]} features\")\n",
    "        print(f\"üìà Distribuci√≥n objetivo: {y.value_counts().to_dict()}\")\n",
    "        print(f\"üéØ Features del ensemble: {list(X.columns)}\")\n",
    "        \n",
    "        # Dividir datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Escalar features\n",
    "        X_train_scaled = self.ensemble_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.ensemble_scaler.transform(X_test)\n",
    "        \n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        \n",
    "        # Entrenar modelos\n",
    "        results = {}\n",
    "        print(\"KNN Start\")\n",
    "        # KNN\n",
    "        results['KNN'] = self.train_knn_model(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        print(\"KNN End\")\n",
    "\n",
    "        print(\"RF Start\")\n",
    "        # Random Forest (no necesita escalado, pero lo usaremos para consistencia)\n",
    "        results['RandomForest'] = self.train_random_forest_model(X_train, y_train, X_test, y_test)\n",
    "        print(\"RF Start\")\n",
    "\n",
    "        print(\"MLP Start\")\n",
    "        # MLP\n",
    "        results['MLP'] = self.train_mlp_model(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        print(\"KNN MLP\")\n",
    "        # Resumen de resultados\n",
    "        self.print_results_summary(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_casino_won(self, initial_amount, avg_bet, cluster, weekday=1, weekend=0, month=1, model_name='best'):\n",
    "        \"\"\"\n",
    "        Predice si el casino ganar√° para una sesi√≥n espec√≠fica\n",
    "        \"\"\"\n",
    "        # Generar predicciones de los modelos individuales\n",
    "        predictions = self.predict_session(initial_amount, avg_bet, cluster, weekday, weekend, month)\n",
    "        \n",
    "        if 'error' in predictions:\n",
    "            return predictions\n",
    "        \n",
    "        # Crear feature vector para ensemble\n",
    "        feature_vector = pd.DataFrame({\n",
    "            'time_on_device': [predictions['time_on_device']],\n",
    "            'bet_total': [predictions['bet_total']],\n",
    "            'win_total': [predictions['win_total']],\n",
    "            'initial_amount': [initial_amount],\n",
    "            'cluster': [cluster],\n",
    "            'avg_bet': [avg_bet]\n",
    "        })\n",
    "        \n",
    "        # Escalar features\n",
    "        feature_vector_scaled = self.ensemble_scaler.transform(feature_vector)\n",
    "        feature_vector_scaled = pd.DataFrame(feature_vector_scaled, columns=feature_vector.columns)\n",
    "        \n",
    "        # Seleccionar modelo\n",
    "        if model_name == 'best':\n",
    "            # Aqu√≠ podr√≠as implementar l√≥gica para seleccionar el mejor modelo\n",
    "            # Por ahora usaremos Random Forest como default\n",
    "            model_name = 'RandomForest'\n",
    "        \n",
    "        if model_name not in self.trained_classifiers:\n",
    "            return {\"error\": f\"Modelo {model_name} no encontrado\"}\n",
    "        \n",
    "        model = self.trained_classifiers[model_name]\n",
    "        \n",
    "        # Hacer predicci√≥n\n",
    "        if model_name == 'RandomForest':\n",
    "            # Random Forest no usa escalado\n",
    "            casino_won_pred = model.predict(feature_vector)[0]\n",
    "            casino_won_proba = model.predict_proba(feature_vector)[0]\n",
    "        else:\n",
    "            # KNN y MLP usan escalado\n",
    "            casino_won_pred = model.predict(feature_vector_scaled)[0]\n",
    "            casino_won_proba = model.predict_proba(feature_vector_scaled)[0]\n",
    "        \n",
    "        result = {\n",
    "            'casino_won_prediction': bool(casino_won_pred),\n",
    "            'casino_won_probability': float(casino_won_proba[1]),  # Probabilidad de que casino gane\n",
    "            'player_win_probability': float(casino_won_proba[0]),  # Probabilidad de que jugador gane\n",
    "            'model_used': model_name,\n",
    "            'individual_predictions': {\n",
    "                'time_on_device': predictions['time_on_device'],\n",
    "                'bet_total': predictions['bet_total'],\n",
    "                'win_total': predictions['win_total']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def print_results_summary(self, results):\n",
    "        \"\"\"Imprime un resumen comparativo de todos los modelos\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä RESUMEN COMPARATIVO DE MODELOS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        summary_df = pd.DataFrame({\n",
    "            'Modelo': list(results.keys()),\n",
    "            'Accuracy': [results[model]['accuracy'] for model in results.keys()],\n",
    "            'AUC-ROC': [results[model]['auc_score'] for model in results.keys()]\n",
    "        })\n",
    "        \n",
    "        summary_df = summary_df.sort_values('AUC-ROC', ascending=False)\n",
    "        print(summary_df.to_string(index=False))\n",
    "        \n",
    "        best_model = summary_df.iloc[0]['Modelo']\n",
    "        print(f\"\\nüèÜ Mejor modelo: {best_model}\")\n",
    "        print(f\"   AUC-ROC: {summary_df.iloc[0]['AUC-ROC']:.4f}\")\n",
    "        print(f\"   Accuracy: {summary_df.iloc[0]['Accuracy']:.4f}\")\n",
    "    \n",
    "    def save_ensemble_models(self, save_path):\n",
    "        \"\"\"Guarda los modelos entrenados usando joblib\"\"\"\n",
    "        import os\n",
    "        \n",
    "        # Crear directorio si no existe\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        for model_name, model in self.trained_classifiers.items():\n",
    "            model_path = f\"{save_path}/ensemble_{model_name.lower()}_model.pkl\"\n",
    "            joblib.dump(model, model_path)\n",
    "            print(f\"‚úÖ Modelo {model_name} guardado en: {model_path}\")\n",
    "        \n",
    "        # Guardar scaler con joblib\n",
    "        scaler_path = f\"{save_path}/ensemble_scaler.pkl\"\n",
    "        joblib.dump(self.ensemble_scaler, scaler_path)\n",
    "        print(f\"‚úÖ Scaler guardado en: {scaler_path}\")\n",
    "    \n",
    "    def load_ensemble_models(self, load_path):\n",
    "        \"\"\"Carga los modelos ensemble previamente entrenados\"\"\"\n",
    "        try:\n",
    "            # Cargar modelos ensemble\n",
    "            model_files = {\n",
    "                'KNN': f\"{load_path}/ensemble_knn_model.pkl\",\n",
    "                'RandomForest': f\"{load_path}/ensemble_randomforest_model.pkl\", \n",
    "                'MLP': f\"{load_path}/ensemble_mlp_model.pkl\"\n",
    "            }\n",
    "            \n",
    "            for model_name, model_path in model_files.items():\n",
    "                try:\n",
    "                    self.trained_classifiers[model_name] = joblib.load(model_path)\n",
    "                    print(f\"‚úÖ Modelo {model_name} cargado desde: {model_path}\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"‚ö†Ô∏è Modelo {model_name} no encontrado en: {model_path}\")\n",
    "            \n",
    "            # Cargar scaler\n",
    "            scaler_path = f\"{load_path}/ensemble_scaler.pkl\"\n",
    "            self.ensemble_scaler = joblib.load(scaler_path)\n",
    "            print(f\"‚úÖ Scaler cargado desde: {scaler_path}\")\n",
    "            \n",
    "            print(f\"üéØ Modelos ensemble cargados: {list(self.trained_classifiers.keys())}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cargando modelos ensemble: {e}\")\n",
    "            raise\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE USO Y EJEMPLOS\n",
    "# ============================================================================\n",
    "\n",
    "def main_train_ensemble_sampled():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para entrenar el ensemble con muestreo (RECOMENDADO)\n",
    "    \"\"\"\n",
    "    # Configurar rutas de modelos (ajusta seg√∫n tus rutas)\n",
    "    model_paths = {\n",
    "        'tiempo_model': 'path/to/tiempo_model.h5',\n",
    "        'bet_model': 'path/to/bet_model.h5', \n",
    "        'win_model': 'path/to/win_model.h5',\n",
    "        'tiempo_scaler': 'path/to/tiempo_scaler.pkl',\n",
    "        'bet_scaler': 'path/to/bet_scaler.pkl',\n",
    "        'win_scaler': 'path/to/win_scaler.pkl'\n",
    "    }\n",
    "    \n",
    "    # Cargar tus datos (ajusta seg√∫n tu dataset)\n",
    "    # data = pd.read_csv('path/to/your/data.csv')\n",
    "    \n",
    "    # Inicializar modelo ensemble\n",
    "    ensemble_model = CasinoEnsembleModelOptimized(model_paths)\n",
    "    \n",
    "    # Entrenar con muestreo estratificado (10K sesiones)\n",
    "    print(\"üéØ Entrenamiento con muestreo estratificado...\")\n",
    "    results = ensemble_model.train_ensemble_models_sampled(\n",
    "        data=data,  # Tu DataFrame\n",
    "        sample_size=10000,  # Usar 10K sesiones en lugar de 200K+\n",
    "        target_col='CASINO_WON',\n",
    "        test_size=0.2\n",
    "    )\n",
    "    \n",
    "    # Guardar modelos\n",
    "    ensemble_model.save_ensemble_models('models/ensemble/')\n",
    "    \n",
    "    return ensemble_model, results\n",
    "\n",
    "def main_train_ensemble_full():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para entrenar con dataset completo (OPTIMIZADO)\n",
    "    \"\"\"\n",
    "    # Configurar rutas de modelos\n",
    "    model_paths = {\n",
    "        'tiempo_model': 'path/to/tiempo_model.h5',\n",
    "        'bet_model': 'path/to/bet_model.h5', \n",
    "        'win_model': 'path/to/win_model.h5',\n",
    "        'tiempo_scaler': 'path/to/tiempo_scaler.pkl',\n",
    "        'bet_scaler': 'path/to/bet_scaler.pkl',\n",
    "        'win_scaler': 'path/to/win_scaler.pkl'\n",
    "    }\n",
    "    \n",
    "    # Cargar datos\n",
    "    # data = pd.read_csv('path/to/your/data.csv')\n",
    "    \n",
    "    # Inicializar modelo ensemble\n",
    "    ensemble_model = CasinoEnsembleModelOptimized(model_paths)\n",
    "    \n",
    "    # Entrenar con dataset completo (procesamiento batch optimizado)\n",
    "    print(\"üöÄ Entrenamiento con dataset completo (procesamiento batch)...\")\n",
    "    results = ensemble_model.train_ensemble_models(\n",
    "        data=data,\n",
    "        target_col='CASINO_WON',\n",
    "        test_size=0.2\n",
    "    )\n",
    "    \n",
    "    # Guardar modelos\n",
    "    ensemble_model.save_ensemble_models('models/ensemble/')\n",
    "    \n",
    "    return ensemble_model, results\n",
    "\n",
    "def example_predictions():\n",
    "    \"\"\"\n",
    "    Ejemplo de c√≥mo hacer predicciones\n",
    "    \"\"\"\n",
    "    # Cargar modelo entrenado\n",
    "    model_paths = {\n",
    "        'tiempo_model': 'path/to/tiempo_model.h5',\n",
    "        'bet_model': 'path/to/bet_model.h5', \n",
    "        'win_model': 'path/to/win_model.h5',\n",
    "        'tiempo_scaler': 'path/to/tiempo_scaler.pkl',\n",
    "        'bet_scaler': 'path/to/bet_scaler.pkl',\n",
    "        'win_scaler': 'path/to/win_scaler.pkl'\n",
    "    }\n",
    "    \n",
    "    ensemble_model = CasinoEnsembleModelOptimized(model_paths)\n",
    "    \n",
    "    # Cargar modelos ensemble pre-entrenados\n",
    "    ensemble_model.load_ensemble_models('models/ensemble/')\n",
    "    \n",
    "    # Hacer predicciones individuales\n",
    "    examples = [\n",
    "        (100, 5, 0),    # $100 inicial, $5 apuesta promedio, cluster 0\n",
    "        (500, 20, 1),   # $500 inicial, $20 apuesta promedio, cluster 1  \n",
    "        (50, 2, 2),     # $50 inicial, $2 apuesta promedio, cluster 2\n",
    "    ]\n",
    "    \n",
    "    print(\"üé≤ Ejemplos de predicciones:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for initial, avg_bet, cluster in examples:\n",
    "        result = ensemble_model.predict_casino_won(\n",
    "            initial_amount=initial,\n",
    "            avg_bet=avg_bet,\n",
    "            cluster=cluster,\n",
    "            model_name='RandomForest'  # o 'KNN', 'MLP', 'best'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüí∞ Sesi√≥n: ${initial} inicial, ${avg_bet} apuesta promedio, cluster {cluster}\")\n",
    "        print(f\"   üéØ Casino ganar√°: {result['casino_won_prediction']}\")\n",
    "        print(f\"   üìä Probabilidad casino: {result['casino_won_probability']:.3f}\")\n",
    "        print(f\"   üìä Probabilidad jugador: {result['player_win_probability']:.3f}\")\n",
    "        print(f\"   ü§ñ Modelo usado: {result['model_used']}\")\n",
    "        print(f\"   üìà Predicciones individuales:\")\n",
    "        print(f\"       Tiempo en dispositivo: {result['individual_predictions']['time_on_device']:.1f} min\")\n",
    "        print(f\"       Apuesta total: ${result['individual_predictions']['bet_total']:.2f}\")\n",
    "        print(f\"       Ganancia total: ${result['individual_predictions']['win_total']:.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# INSTRUCCIONES DE USO\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "C√ìMO USAR ESTE C√ìDIGO:\n",
    "\n",
    "1. OPCI√ìN R√ÅPIDA (RECOMENDADA) - Muestreo estratificado:\n",
    "   \n",
    "   ensemble_model, results = main_train_ensemble_sampled()\n",
    "   \n",
    "   - Usa solo 10,000 sesiones representativas\n",
    "   - Tiempo estimado: 15-30 minutos\n",
    "   - Mantiene distribuci√≥n de clases\n",
    "   - Ideal para desarrollo y pruebas\n",
    "\n",
    "2. OPCI√ìN COMPLETA - Dataset completo optimizado:\n",
    "   \n",
    "   ensemble_model, results = main_train_ensemble_full()\n",
    "   \n",
    "   - Usa todo el dataset con procesamiento batch\n",
    "   - Tiempo estimado: 1-2 horas (vs 4+ horas original)\n",
    "   - Mejor rendimiento final\n",
    "   - Para producci√≥n\n",
    "\n",
    "3. HACER PREDICCIONES:\n",
    "   \n",
    "   example_predictions()\n",
    "   \n",
    "   - Requiere modelos ya entrenados\n",
    "   - Predicciones instant√°neas\n",
    "\n",
    "CONFIGURACI√ìN NECESARIA:\n",
    "\n",
    "1. Actualizar model_paths con tus rutas reales:\n",
    "   model_paths = {\n",
    "       'tiempo_model': 'tu/ruta/tiempo_model.h5',\n",
    "       'bet_model': 'tu/ruta/bet_model.h5', \n",
    "       'win_model': 'tu/ruta/win_model.h5',\n",
    "       'tiempo_scaler': 'tu/ruta/tiempo_scaler.pkl',\n",
    "       'bet_scaler': 'tu/ruta/bet_scaler.pkl',\n",
    "       'win_scaler': 'tu/ruta/win_scaler.pkl'\n",
    "   }\n",
    "\n",
    "2. Cargar tu dataset:\n",
    "   data = pd.read_csv('tu/dataset.csv')\n",
    "   \n",
    "3. Verificar columnas requeridas:\n",
    "   - INITIAL_AMOUNT\n",
    "   - AVG_BET  \n",
    "   - Cluster\n",
    "   - CASINO_WON (target)\n",
    "\n",
    "MEJORAS INCLUIDAS:\n",
    "\n",
    "‚úÖ Procesamiento batch (1000x m√°s r√°pido)\n",
    "‚úÖ Muestreo estratificado \n",
    "‚úÖ Progreso en tiempo real\n",
    "‚úÖ Manejo robusto de errores\n",
    "‚úÖ Guardado/carga optimizada\n",
    "‚úÖ Estad√≠sticas detalladas\n",
    "‚úÖ Comparaci√≥n de modelos\n",
    "‚úÖ Predicciones individuales\n",
    "‚úÖ Documentaci√≥n completa\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Descomentar la opci√≥n que prefieras:\n",
    "    \n",
    "    # OPCI√ìN 1: Entrenamiento r√°pido con muestra\n",
    "    # ensemble_model, results = main_train_ensemble_sampled()\n",
    "    \n",
    "    # OPCI√ìN 2: Entrenamiento completo optimizado  \n",
    "    # ensemble_model, results = main_train_ensemble_full()\n",
    "    \n",
    "    # OPCI√ìN 3: Hacer predicciones (requiere modelos entrenados)\n",
    "    # example_predictions()\n",
    "    \n",
    "    print(\"üöÄ Ensemble Model listo para usar!\")\n",
    "    print(\"üìñ Lee las instrucciones en los comentarios para comenzar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872be1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data_general[['INITIAL_AMOUNT', 'AVG_BET', 'Cluster', 'Weekday', 'Weekend', 'Month', 'CASINO_WON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29beb226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     190755\n",
       "False     18324\n",
       "Name: CASINO_WON, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['CASINO_WON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1d129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     19324\n",
       "False    18324\n",
       "Name: CASINO_WON, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separar las clases\n",
    "casino_won_true = df_train[df_train['CASINO_WON'] == True]\n",
    "casino_won_false = df_train[df_train['CASINO_WON'] == False]\n",
    "\n",
    "# Tomar una muestra aleatoria de la clase mayoritaria del tama√±o de la minoritaria\n",
    "casino_won_true_sampled = resample(casino_won_true, \n",
    "                                   replace=False,  # sin reemplazo\n",
    "                                   n_samples=len(casino_won_false) + 1000,  # mismo tama√±o que False\n",
    "                                   random_state=42)  # para reproducibilidad\n",
    "\n",
    "# Combinar las clases\n",
    "df_balanced = pd.concat([casino_won_true_sampled, casino_won_false])\n",
    "\n",
    "# Mezclar el dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_balanced['CASINO_WON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba9d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 09:48:48.190255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todos los modelos y scalers cargados correctamente\n",
      "üöÄ Iniciando entrenamiento de modelos ensemble...\n",
      "üìù Las features time_on_device, bet_total, win_total se generar√°n desde los modelos pre-entrenados\n",
      "üìã Columnas disponibles: ['INITIAL_AMOUNT', 'AVG_BET', 'Cluster', 'Weekday', 'Weekend', 'Month', 'CASINO_WON']\n",
      "üìä Dataset shape: (37648, 7)\n",
      "üîÑ Generando predicciones usando modelos individuales (procesamiento batch)...\n",
      "üîÑ Procesando 37648 sesiones en 38 lotes de 1000...\n",
      "üì¶ Procesando lote 1/38 (1000 sesiones)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 09:48:53.743270: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Lote 1 completado. Progreso: 2.7%\n",
      "üì¶ Procesando lote 2/38 (1000 sesiones)...\n",
      "‚úÖ Lote 2 completado. Progreso: 5.3%\n",
      "üì¶ Procesando lote 3/38 (1000 sesiones)...\n",
      "‚úÖ Lote 3 completado. Progreso: 8.0%\n",
      "üì¶ Procesando lote 4/38 (1000 sesiones)...\n",
      "‚úÖ Lote 4 completado. Progreso: 10.6%\n",
      "üì¶ Procesando lote 5/38 (1000 sesiones)...\n",
      "‚úÖ Lote 5 completado. Progreso: 13.3%\n",
      "üì¶ Procesando lote 6/38 (1000 sesiones)...\n",
      "‚úÖ Lote 6 completado. Progreso: 15.9%\n",
      "üì¶ Procesando lote 7/38 (1000 sesiones)...\n",
      "‚úÖ Lote 7 completado. Progreso: 18.6%\n",
      "üì¶ Procesando lote 8/38 (1000 sesiones)...\n",
      "‚úÖ Lote 8 completado. Progreso: 21.2%\n",
      "üì¶ Procesando lote 9/38 (1000 sesiones)...\n",
      "‚úÖ Lote 9 completado. Progreso: 23.9%\n",
      "üì¶ Procesando lote 10/38 (1000 sesiones)...\n",
      "‚úÖ Lote 10 completado. Progreso: 26.6%\n",
      "üì¶ Procesando lote 11/38 (1000 sesiones)...\n",
      "‚úÖ Lote 11 completado. Progreso: 29.2%\n",
      "üì¶ Procesando lote 12/38 (1000 sesiones)...\n",
      "‚úÖ Lote 12 completado. Progreso: 31.9%\n",
      "üì¶ Procesando lote 13/38 (1000 sesiones)...\n",
      "‚úÖ Lote 13 completado. Progreso: 34.5%\n",
      "üì¶ Procesando lote 14/38 (1000 sesiones)...\n",
      "‚úÖ Lote 14 completado. Progreso: 37.2%\n",
      "üì¶ Procesando lote 15/38 (1000 sesiones)...\n",
      "‚úÖ Lote 15 completado. Progreso: 39.8%\n",
      "üì¶ Procesando lote 16/38 (1000 sesiones)...\n",
      "‚úÖ Lote 16 completado. Progreso: 42.5%\n",
      "üì¶ Procesando lote 17/38 (1000 sesiones)...\n",
      "‚úÖ Lote 17 completado. Progreso: 45.2%\n",
      "üì¶ Procesando lote 18/38 (1000 sesiones)...\n",
      "‚úÖ Lote 18 completado. Progreso: 47.8%\n",
      "üì¶ Procesando lote 19/38 (1000 sesiones)...\n",
      "‚úÖ Lote 19 completado. Progreso: 50.5%\n",
      "üì¶ Procesando lote 20/38 (1000 sesiones)...\n",
      "‚úÖ Lote 20 completado. Progreso: 53.1%\n",
      "üì¶ Procesando lote 21/38 (1000 sesiones)...\n",
      "‚úÖ Lote 21 completado. Progreso: 55.8%\n",
      "üì¶ Procesando lote 22/38 (1000 sesiones)...\n",
      "‚úÖ Lote 22 completado. Progreso: 58.4%\n",
      "üì¶ Procesando lote 23/38 (1000 sesiones)...\n",
      "‚úÖ Lote 23 completado. Progreso: 61.1%\n",
      "üì¶ Procesando lote 24/38 (1000 sesiones)...\n",
      "‚úÖ Lote 24 completado. Progreso: 63.7%\n",
      "üì¶ Procesando lote 25/38 (1000 sesiones)...\n",
      "‚úÖ Lote 25 completado. Progreso: 66.4%\n",
      "üì¶ Procesando lote 26/38 (1000 sesiones)...\n",
      "‚úÖ Lote 26 completado. Progreso: 69.1%\n",
      "üì¶ Procesando lote 27/38 (1000 sesiones)...\n",
      "‚úÖ Lote 27 completado. Progreso: 71.7%\n",
      "üì¶ Procesando lote 28/38 (1000 sesiones)...\n",
      "‚úÖ Lote 28 completado. Progreso: 74.4%\n",
      "üì¶ Procesando lote 29/38 (1000 sesiones)...\n",
      "‚úÖ Lote 29 completado. Progreso: 77.0%\n",
      "üì¶ Procesando lote 30/38 (1000 sesiones)...\n",
      "‚úÖ Lote 30 completado. Progreso: 79.7%\n",
      "üì¶ Procesando lote 31/38 (1000 sesiones)...\n",
      "‚úÖ Lote 31 completado. Progreso: 82.3%\n",
      "üì¶ Procesando lote 32/38 (1000 sesiones)...\n",
      "‚úÖ Lote 32 completado. Progreso: 85.0%\n",
      "üì¶ Procesando lote 33/38 (1000 sesiones)...\n",
      "‚úÖ Lote 33 completado. Progreso: 87.7%\n",
      "üì¶ Procesando lote 34/38 (1000 sesiones)...\n",
      "‚úÖ Lote 34 completado. Progreso: 90.3%\n",
      "üì¶ Procesando lote 35/38 (1000 sesiones)...\n",
      "‚úÖ Lote 35 completado. Progreso: 93.0%\n",
      "üì¶ Procesando lote 36/38 (1000 sesiones)...\n",
      "‚úÖ Lote 36 completado. Progreso: 95.6%\n",
      "üì¶ Procesando lote 37/38 (1000 sesiones)...\n",
      "‚úÖ Lote 37 completado. Progreso: 98.3%\n",
      "üì¶ Procesando lote 38/38 (648 sesiones)...\n",
      "‚úÖ Lote 38 completado. Progreso: 100.0%\n",
      "‚úÖ Features del ensemble generadas exitosamente:\n",
      "   - 37648 sesiones procesadas\n",
      "   - Variables generadas por modelos MLP: time_on_device, bet_total, win_total\n",
      "   - Variables originales: initial_amount, cluster, avg_bet\n",
      "   - Total features para clasificaci√≥n: 6\n",
      "\n",
      "üìä Estad√≠sticas de predicciones generadas:\n",
      "   time_on_device: 20.05 ¬± 26.68\n",
      "   bet_total: $1082.65 ¬± $2327.12\n",
      "   win_total: $1022.99 ¬± $2680.53\n",
      "üìä Datos preparados: 37648 muestras, 6 features\n",
      "üìà Distribuci√≥n objetivo: {True: 19324, False: 18324}\n",
      "üéØ Features del ensemble: ['time_on_device', 'bet_total', 'win_total', 'initial_amount', 'cluster', 'avg_bet']\n",
      "KNN Start\n",
      "\n",
      "üîπ Entrenando modelo KNN...\n",
      "Mejores par√°metros: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "Accuracy: 0.5958\n",
      "AUC-ROC: 0.6397\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.54      0.56      3665\n",
      "        True       0.60      0.65      0.62      3865\n",
      "\n",
      "    accuracy                           0.60      7530\n",
      "   macro avg       0.60      0.59      0.59      7530\n",
      "weighted avg       0.60      0.60      0.59      7530\n",
      "\n",
      "KNN End\n",
      "RF Start\n",
      "\n",
      "üå≥ Entrenando modelo Random Forest...\n",
      "Mejores par√°metros: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Accuracy: 0.6231\n",
      "AUC-ROC: 0.6730\n",
      "\n",
      "Importancia de features:\n",
      "          feature  importance\n",
      "0  time_on_device        0.28\n",
      "2       win_total        0.23\n",
      "3  initial_amount        0.20\n",
      "1       bet_total        0.17\n",
      "5         avg_bet        0.10\n",
      "4         cluster        0.02\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.42      0.52      3665\n",
      "        True       0.60      0.81      0.69      3865\n",
      "\n",
      "    accuracy                           0.62      7530\n",
      "   macro avg       0.64      0.62      0.61      7530\n",
      "weighted avg       0.64      0.62      0.61      7530\n",
      "\n",
      "RF Start\n",
      "MLP Start\n",
      "\n",
      "üß† Entrenando modelo MLP...\n",
      "Mejores par√°metros: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.01}\n",
      "Accuracy: 0.6205\n",
      "AUC-ROC: 0.6662\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.40      0.51      3665\n",
      "        True       0.59      0.83      0.69      3865\n",
      "\n",
      "    accuracy                           0.62      7530\n",
      "   macro avg       0.64      0.61      0.60      7530\n",
      "weighted avg       0.64      0.62      0.60      7530\n",
      "\n",
      "KNN MLP\n",
      "\n",
      "============================================================\n",
      "üìä RESUMEN COMPARATIVO DE MODELOS\n",
      "============================================================\n",
      "      Modelo  Accuracy  AUC-ROC\n",
      "RandomForest      0.62     0.67\n",
      "         MLP      0.62     0.67\n",
      "         KNN      0.60     0.64\n",
      "\n",
      "üèÜ Mejor modelo: RandomForest\n",
      "   AUC-ROC: 0.6730\n",
      "   Accuracy: 0.6231\n"
     ]
    }
   ],
   "source": [
    "model_paths = {\n",
    "    'tiempo_model': '../../../models/tiempo_model.h5',\n",
    "    'tiempo_scaler': '../../../models/tiempo_scaler.pkl',\n",
    "    'bet_model': '../../../models/bet_model.h5',\n",
    "    'bet_scaler': '../../../models/bet_scaler.pkl',\n",
    "    'win_model': '../../../models/win_model.h5',\n",
    "    'win_scaler': '../../../models/win_scaler.pkl'\n",
    "}\n",
    "\n",
    "# Crear instancia del modelo ensemble\n",
    "ensemble_model = CasinoEnsembleModelOptimized(model_paths)\n",
    "results = ensemble_model.train_ensemble_models(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790735b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo KNN guardado en: modelo.pkl/ensemble_knn_model.pkl\n",
      "‚úÖ Modelo RandomForest guardado en: modelo.pkl/ensemble_randomforest_model.pkl\n",
      "‚úÖ Modelo MLP guardado en: modelo.pkl/ensemble_mlp_model.pkl\n",
      "‚úÖ Scaler guardado en: modelo.pkl/ensemble_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.save_ensemble_models('modelo.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
